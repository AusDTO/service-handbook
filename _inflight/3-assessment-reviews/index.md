---
title: Assessment reviews
section: 3-assessment-reviews
index: true
---

The in-flight checkins should be reviewed so that the team has a good overall view of their progress. Your reviews will be encapsulated in a summary report.

## Monitor service progress


You will run an assessment review at 3 transition points of the service design and delivery process:

1.	At the end of Alpha, when the service has green ratings against criteria 1, 2 and 3 and can show progress on the other criteria. This review informs the Alpha assessment report on the service. 
2.	Before public Beta but before the public beta is launched, when the service has green ratings against all criteria. This review informs the Beta assessment report on the service.
3.	Before Live, when the service has green ratings against all criteria, and the public beta has good digital take up and is working better than the current live service (if there is one). This review is pre-live and will inform the Live assessment report on the service.

## Schedule the review during check-in


The assessment review should run as part of the regular check-in, but you may want to schedule extra time. The assessors and the delivery team will reach an agreement on when the stage is completed.

## Write report

Assessment reports are written after the 3 reviews mentioned previously. The reports are published on the DTO website.


Write the assessment report using the [report templates](https://github.com/AusDTO/service-handbook/tree/gh-pages/_inflight/5-tools). Refer to progress against all the relevant criteria and use the notes and data you have recorded at your regular check-ins to inform your report. 

The reports are an opportunity to showcase what the digital delivery team has done and to help other teams. Draw out all the elements of good performance against the Standard. 

Give recommendations for what needs to be done next. Be clear and unambiguous in your language. Your role is to mentor the digital delivery team and help them to understand what they might do to make their service simpler, clearer and faster for everyone. It’s a learning and development partnership, you are helping the digital delivery team acquire new skills and new ways of working.

If you are unsure how to write your report:

*	look at other assessment reports
*	talk to other assessors, or
*	email [standard@digital.gov.au](mailto:standard@digital.gov.au) for advice. 

If the service is moving to public beta, source code repositories need to be opened and published and the metrics on the service needs to be ready to appear on the performance dashboard.

### Submit report for publishing

Email the report to the Digital Service Standard team [standard@digital.gov.au](mailto:standard@digital.gov.au) within 3 days of the assessment.

Assessment reports are published within 2 days.

## <a name="escalation">Escalating problems</a>

You should resolve any disagreements between assessors and the digital delivery team as quickly as possible so they don’t block progress. 

There’s an escalation process to help with this.

If you need support or advice raise it with other assessors within your organisation first.
The Digital Transformation Office (DTO) has an Assessor Guild where we solve problems as a group.

If you need more help, [contact the Standards team](mailto:standard@digital.gov.au).

### Triggers to escalate

*	Red rating 2 weeks in a row, or earlier with agreement from all assessors
*   Disagreement between the assessors (as a group) and the service team that is not resolved within 2 weeks.
*   Disagreements between assessors. This should be escalated straight away.
*   Any extension/delay in progress between stages. 

### Who can escalate?

*	Lead assessor, with agreement of other assessors.
*	Product manager or service manager.

If the service is a high volume transactional service and/or if it is delivered through the DTO’s delivery hub you must follow the DTO chain of responsibility.

Agencies should use their own governance processes to identify their escalation chain.

DTO chain of responsibility:

1.	Talk to the **head of the relevant stream** and/or seek the relevant guild or community input to facilitate resolution. Take care discussing with others if the issue is sensitive.
2.	If not resolved, talk to the DTO’s **Head of Service Design**, who will facilitate a resolution. If it cannot be resolved within 1 week they will agree to escalate further. Any action and discussion must be documented in the RAG rating.
3.	If resolution is not achieved, escalate to the DTO’s **Head of Delivery**. The escalation must be sponsored by the Head of Service Design. Write a 1 page brief explaining why the issue was unable to be resolved and what action is required.
4.	If the issue is unable to be resolved within the DTO, the Head of Delivery may need to work with **senior management in the APS agency** to achieve resolution. All discussion should be documented.
5.	Escalation to the **CEO** is the last resort. It would be necessary if the Head of the APS agency is involved. This should be managed by the Head of Delivery, Head of Service Design, Head of Product and the Head of the Digital Service Standard team. 

### Documenting for escalation

As part of your check-in notes you should provide a concise summary of the problem and what needs to be done to resolve the issue. Build on this if the problem continues or needs to be escalated.

Include:

*	the points of difference, including the delivery team’s view
*	how the issue was identified
*	how it was unable to be resolved in the regular check-ins
*	links to more detailed notes.

Do not assume that the people you are escalating to already know the required background information.

All parties should have discussed the issue. Neither service team nor assessors should be surprised that this is being escalated.

For **high volume transactional services** reporting into the DTO, the check-in RAG ratings should have identified the issue as it was developing, so it shouldn’t come as a surprise if it is escalated.
